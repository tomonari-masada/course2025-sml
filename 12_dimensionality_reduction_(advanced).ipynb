{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1ozhlLBREdR8ARlJQ-ealVD2oaNnwVXr6",
      "authorship_tag": "ABX9TyNGPV85Laf01q74u/EasExw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomonari-masada/course2025-sml/blob/main/12_dimensionality_reduction_(advanced).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvpZvwPRb9o7"
      },
      "source": [
        "# Dimensionality reduction （発展編）"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* GPUが使えるようにランタイムを設定しておく。"
      ],
      "metadata": {
        "id": "-CIBjDn8Hegn"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUWkKiFEb6Yz"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "\n",
        "%config InlineBackend.figure_format = 'retina'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BG5A7NE9cO25"
      },
      "source": [
        "train = pd.read_csv('/content/drive/MyDrive/data/sign_mnist_train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/data/sign_mnist_test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogZNLsfQcicb"
      },
      "source": [
        "# Setting the label and the feature columns\n",
        "y_train = train.loc[:,'label'].values\n",
        "X_train = train.loc[:,'pixel1':].values\n",
        "y_test = test.loc[:,'label'].values\n",
        "X_test = test.loc[:,'pixel1':].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJtPmnyy_Nxw"
      },
      "source": [
        "## データの前処理\n",
        "* scikit-learnのドキュメンテーションにあるやり方に倣った。\n",
        "  * まずtraining set全体での各ピクセルの平均値を引き算し・・・\n",
        "  * 次に各画像内でのローカルな平均値を引き算する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yb6T9gw7dze3"
      },
      "source": [
        "# global centering\n",
        "train_mean = X_train.mean(axis=0)\n",
        "X_train_centered = X_train - train_mean\n",
        "X_test_centered = X_test - train_mean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlyIw2JtcB3B"
      },
      "source": [
        "# local centering\n",
        "X_train_centered = X_train_centered - X_train_centered.mean(axis=1).reshape(-1, 1)\n",
        "X_test_centered = X_test_centered - X_test_centered.mean(axis=1).reshape(-1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCmlv8N6czPZ"
      },
      "source": [
        "plt.imshow(X_train_centered[0,:].reshape(28,28), cmap=plt.cm.gray);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEkXJO2__3oy"
      },
      "source": [
        "## 次元圧縮手法によるデータの再構成(reconstruction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Mvtk_5UAeVJ"
      },
      "source": [
        "* 画像を複数描画する関数を定義しておく。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Et8a2Z3ZgzjG"
      },
      "source": [
        "def plot_gallery(title, images, n_col=3, n_row=3, cmap=plt.cm.gray):\n",
        "  plt.figure(figsize=(2. * n_col, 2.26 * n_row))\n",
        "  plt.suptitle(title, size=16)\n",
        "  for i, comp in enumerate(images):\n",
        "    plt.subplot(n_row, n_col, i + 1)\n",
        "    vmax = max(comp.max(), -comp.min())\n",
        "    plt.imshow(\n",
        "        comp.reshape(28, 28),\n",
        "        cmap=cmap,\n",
        "        interpolation=\"nearest\",\n",
        "        vmin=-vmax,\n",
        "        vmax=vmax,\n",
        "    )\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "  plt.subplots_adjust(0.01, 0.05, 0.99, 0.93, 0.04, 0.);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSpYTj00g_Xw"
      },
      "source": [
        "plot_gallery(\"sign mnist\", X_train_centered[:9], n_row=3, n_col=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_components = 30\n",
        "n_instances, instance_dim = X_train_centered.shape\n",
        "n_test_instances = X_test_centered.shape[0]"
      ],
      "metadata": {
        "id": "-aCiUcK8E2ja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_torch = torch.tensor(X_train_centered, dtype=torch.float, device=\"cuda\")\n",
        "\n",
        "bases = torch.randn((n_components, instance_dim), requires_grad=True, device=\"cuda\")\n",
        "coefficients = torch.randn((n_instances, n_components), requires_grad=True, device=\"cuda\")\n",
        "\n",
        "optimizer = torch.optim.Adam([bases, coefficients], lr=0.01)\n",
        "criterion = torch.nn.MSELoss()\n",
        "\n",
        "batch_size = 1000\n",
        "n_steps = 0\n",
        "for epoch in range(1000):\n",
        "  random_indices = torch.randperm(n_instances)\n",
        "  for i in range(0, n_instances, batch_size):\n",
        "    indices = random_indices[i:i+batch_size]\n",
        "    optimizer.zero_grad()\n",
        "    reconstruction = torch.softmax(coefficients[indices], dim=1) @ bases\n",
        "    loss = criterion(reconstruction, X_train_torch[indices])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    n_steps += 1\n",
        "    if n_steps % 1000 == 0:\n",
        "      print(f\"step {n_steps} | loss {loss.item():.4f}\")"
      ],
      "metadata": {
        "id": "-G-Zjvh__tXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "components = bases.cpu().detach().numpy()"
      ],
      "metadata": {
        "id": "tMhYmXlNEUCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSGI3__qd1Au"
      },
      "source": [
        "n_col = 6\n",
        "n_row = n_components // n_col + (n_components % n_col != 0)\n",
        "plot_gallery(\n",
        "    f\"{n_components} components\",\n",
        "    components[:n_components],\n",
        "    n_row=n_row,\n",
        "    n_col=n_col,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBgr8flOA9z7"
      },
      "source": [
        "### テストセットに含まれる画像の再構成"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_torch = torch.tensor(X_test_centered, dtype=torch.float, device=\"cuda\")\n",
        "\n",
        "bases.requires_grad = False # basesは固定する。\n",
        "coefficients = torch.randn((n_test_instances, n_components), requires_grad=True, device=\"cuda\")\n",
        "\n",
        "optimizer = torch.optim.Adam([coefficients], lr=0.01)\n",
        "criterion = torch.nn.MSELoss()\n",
        "\n",
        "batch_size = 1000\n",
        "n_steps = 0\n",
        "for epoch in range(1000):\n",
        "  random_indices = torch.randperm(n_test_instances)\n",
        "  for i in range(0, n_test_instances, batch_size):\n",
        "    indices = random_indices[i:i+batch_size]\n",
        "    optimizer.zero_grad()\n",
        "    reconstruction = torch.softmax(coefficients[indices], dim=1) @ bases\n",
        "    loss = criterion(reconstruction, X_test_torch[indices])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    n_steps += 1\n",
        "    if n_steps % 1000 == 0:\n",
        "      print(f\"step {n_steps} | test reconstruction loss {loss.item():.4f}\")"
      ],
      "metadata": {
        "id": "gCJyRiQTCvq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_recon = (torch.softmax(coefficients, dim=1) @ bases).cpu().detach().numpy()"
      ],
      "metadata": {
        "id": "x5KMr37lEgX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMbjELlUd9cf"
      },
      "source": [
        "n_recon_images = 8\n",
        "indices = np.random.randint(X_test.shape[0], size=n_recon_images)\n",
        "plot_gallery(\"original test data\", X_test_centered[indices], n_row=1, n_col=n_recon_images)\n",
        "plot_gallery(\"reconstructed test data\", X_test_recon[indices], n_row=1, n_col=n_recon_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqThCaEVenFw"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}