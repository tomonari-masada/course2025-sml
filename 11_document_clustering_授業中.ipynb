{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomonari-masada/course2025-sml/blob/main/11_document_clustering_%E6%8E%88%E6%A5%AD%E4%B8%AD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhzrBYzaPTv1"
      },
      "source": [
        "# クラスタリング\n",
        "* クラスタリングの代表的な手法であるk平均法を使ってみる。\n",
        "* ついでに、言語モデルを使ったテキストマイニングを体験してみる。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhbnmWrLWjNw"
      },
      "source": [
        "## 例題: 文書クラスタリング"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijV8d58-WC_6"
      },
      "source": [
        "* Transformerベースの日本語対応言語モデルを使って、テキストのベクトル表現を得る。\n",
        "  * Transformerというニューラルネットワークについては、いずれ学びます。\n",
        "  * 有名な解説記事 https://jalammar.github.io/illustrated-transformer/\n",
        "* テキストをベクトルとして表現することを「embedする」と言う。\n",
        "  * embedすることで得られるベクトルのことを「embedding」と言う。\n",
        "* そして、テキストのembeddingをk平均法でクラスタリングする。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hb9tmJnoWU6J"
      },
      "source": [
        "* ランタイムのタイプをGPUにしておく。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hn3VWlDVnXFR"
      },
      "source": [
        "## インストール"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gdwfzW5nYHd"
      },
      "source": [
        "### spaCyの日本語モデル"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 日本語テキストを形態素解析するために使う。\n",
        "  * たぶん、セッションの再起動」は不要。"
      ],
      "metadata": {
        "id": "FsxP7l_dvpkU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwAN7cUWnS3M"
      },
      "outputs": [],
      "source": [
        "!python -m spacy download ja_core_news_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kl6bBezenbZa"
      },
      "source": [
        "### Hugging Faceのdatasetsライブラリ"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ライブドアニュースコーパスを取得するために使う。"
      ],
      "metadata": {
        "id": "wA3D6HJ_vzTY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PluefZCf6y7"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade datasets huggingface_hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyLkN6QuXBWD"
      },
      "source": [
        "### SentenceTransformersライブラリ\n",
        "* 言語モデルを使ってテキストを埋め込む際に便利なライブラリ。\n",
        "  * https://sbert.net/index.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xipZgdSGV5-p"
      },
      "outputs": [],
      "source": [
        "!pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ureiahpCn4Qg"
      },
      "source": [
        "## インポート"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_09KVWCP9Cc"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "import collections\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "import spacy\n",
        "\n",
        "from datasets import load_dataset\n",
        "from transformers import set_seed\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# 再現性の確保\n",
        "set_seed(1234)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTBDLSvzgMuF"
      },
      "source": [
        "## データセット\n",
        "* livedoorニュースコーパスを使う。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvpTDWbAgFc3"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\n",
        "  \"shunk031/livedoor-news-corpus\",\n",
        "  train_ratio=0.8, val_ratio=0.1, test_ratio=0.1,\n",
        "  random_state=42,\n",
        "  shuffle=True,\n",
        "  trust_remote_code=True,\n",
        ")\n",
        "\n",
        "num_categories = len(set(dataset[\"train\"][\"category\"]))\n",
        "\n",
        "category_names = [\n",
        "  'movie-enter',\n",
        "  'it-life-hack',\n",
        "  'kaden-channel',\n",
        "  'topic-news',\n",
        "  'livedoor-homme',\n",
        "  'peachy',\n",
        "  'sports-watch',\n",
        "  'dokujo-tsushin',\n",
        "  'smax',\n",
        "]\n",
        "\n",
        "print(f\"num_categories: {num_categories}\")\n",
        "print(f\"category_names: {category_names}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"train\"][0]"
      ],
      "metadata": {
        "id": "ml3uV37MAZAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSsfXafQlcdm"
      },
      "outputs": [],
      "source": [
        "dataset[\"train\"][\"title\"][:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2H7PUHulfsZ"
      },
      "outputs": [],
      "source": [
        "dataset[\"train\"][\"content\"][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-o2yZ06-QQN4"
      },
      "source": [
        "## 多言語E5による埋め込み"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L11M2E3ca6_2"
      },
      "source": [
        "* Multilingual E5を使う。\n",
        "  * テキストのembeddingにおいて優れている言語モデル。\n",
        "  * 論文 https://arxiv.org/abs/2402.05672\n",
        "  * Hugging Face https://huggingface.co/intfloat/multilingual-e5-large-instruct"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 参考: テキスト埋め込みのleaderboard\n",
        "  * https://huggingface.co/spaces/mteb/leaderboard"
      ],
      "metadata": {
        "id": "b6Fje4mLBLKA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmrIJqThZ20F"
      },
      "source": [
        "* SentenceTransformerを使ったテキストの埋め込みについては、下のWebページを参照。\n",
        "  * https://sbert.net/examples/sentence_transformer/applications/computing-embeddings/README.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRCWin9LA5Y7"
      },
      "outputs": [],
      "source": [
        "model_id = \"intfloat/multilingual-e5-large-instruct\"\n",
        "model = SentenceTransformer(model_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 試しに、一つだけ、テキストを埋め込んでみる。"
      ],
      "metadata": {
        "id": "NlTTugsEApkv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"train\"][0][\"title\"]"
      ],
      "metadata": {
        "id": "VsFkP2JIE1gT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "L3PPiSMVE8bs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.encode(dataset[\"train\"][0][\"title\"])"
      ],
      "metadata": {
        "id": "XHf7OzXWAneU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZ-E1KAFdlj9"
      },
      "source": [
        "* ライブドアニュースコーパスの全タイトルを埋め込む。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yewQUXmGCb6G"
      },
      "outputs": [],
      "source": [
        "embeddings = model.encode(dataset[\"train\"][\"title\"], show_progress_bar=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 埋め込みは普通にNumPyの配列として得られている。"
      ],
      "metadata": {
        "id": "cyQMBYWWyC0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(embeddings)"
      ],
      "metadata": {
        "id": "TiEYb81yyBjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings.shape"
      ],
      "metadata": {
        "id": "EXlWZZ0-F0Lf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7AjcVKTEVMo"
      },
      "source": [
        "* 全記事内容を埋め込むには以下のようにする。  \n",
        "  * RTX3080搭載PCを使うと1分で終わる。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRQW-Gx2EVMo"
      },
      "outputs": [],
      "source": [
        "#content_embeddings = model.encode(dataset[\"train\"][\"content\"], show_progress_bar=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ただし、どのテキストも先頭から512トークンで切られていることに注意。\n",
        "  * 長いテキストは、途中までの内容しかembeddingに反映されない。\n",
        "  * それでも、分類やクラスタリングがうまくいくことも多い。"
      ],
      "metadata": {
        "id": "9pVO40oIWn5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.max_seq_length"
      ],
      "metadata": {
        "id": "bISzb8CzWlRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* トークン数の調べ方\n",
        "  * トークナイザにテキストを分割させる。\n",
        "  * 分割によって得られたトークンの個数を数える。"
      ],
      "metadata": {
        "id": "BS3lrQk_xQLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"train\"][0][\"title\"]"
      ],
      "metadata": {
        "id": "WEUcRU0IHB1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.tokenize([dataset[\"train\"][0][\"title\"]])"
      ],
      "metadata": {
        "id": "wUPlGCKCxJVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(model.tokenize([dataset[\"train\"][0][\"title\"]])['input_ids']).shape[1]"
      ],
      "metadata": {
        "id": "wvOv8r0TxU1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyiMLzsMcz5C"
      },
      "source": [
        "* 埋め込みを保存。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "toeI36FNceR_"
      },
      "outputs": [],
      "source": [
        "with open('embeddings.npy', 'wb') as f:\n",
        "  np.save(f, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSQOagHqEVMo"
      },
      "outputs": [],
      "source": [
        "#with open('content_embeddings.npy', 'wb') as f:\n",
        "#  np.save(f, content_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqbMNNHPc2-F"
      },
      "source": [
        "* 読み込みは以下のようにする。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sSjKGTScknl"
      },
      "outputs": [],
      "source": [
        "with open('embeddings.npy', 'rb') as f:\n",
        "  embeddings = np.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KnwfI4i7EVMp"
      },
      "outputs": [],
      "source": [
        "#with open('content_embeddings.npy', 'rb') as f:\n",
        "#  content_embeddings = np.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EntA_0wuEVMp"
      },
      "source": [
        "## クラスタのラベリングに使う単語の抽出"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 全テキストを形態素解析する。\n",
        "  * 形態素解析＝単語への分割"
      ],
      "metadata": {
        "id": "4VuPO6Q9yvmD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2JKK34DGmVYP"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"ja_core_news_sm\")\n",
        "corpus = []\n",
        "for text in tqdm(dataset[\"train\"][\"title\"]):\n",
        "  corpus.append(\" \".join([token.lemma_ for token in nlp(text)]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"train\"][0][\"title\"]"
      ],
      "metadata": {
        "id": "IWrwhoCMJPDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus[0]"
      ],
      "metadata": {
        "id": "-32b91J5JMFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWmaRgolEVMp"
      },
      "source": [
        "* scikit-learnでTF-IDFを計算する。\n",
        "* `TfidfVectorizer`の`min_df`パラメータは適当に調節する。\n",
        "  * クラスタのラベリングに向かないマイナーな単語が含まれないようにする。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(min_df=20)"
      ],
      "metadata": {
        "id": "uSd5M9K1J1cq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = vectorizer.fit_transform(corpus)"
      ],
      "metadata": {
        "id": "WkJ2JD6QJ7vO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.toarray()"
      ],
      "metadata": {
        "id": "WTozJWm3KTE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "id": "p5PjfEOhKYhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "JliqLF5wMWNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOihcuMrlvMn"
      },
      "outputs": [],
      "source": [
        "vocab = np.array(vectorizer.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9c0q5G0EmDl7"
      },
      "outputs": [],
      "source": [
        "vocab.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "db6qnSlNEVMs"
      },
      "outputs": [],
      "source": [
        "print(list(vocab))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tpz7qe2dEVMs"
      },
      "source": [
        "## ラベリング用単語の埋め込み"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwNXHtnQEVMt"
      },
      "source": [
        "* 各単語について、その単語を含むテキストの埋め込みベクトルの加重平均を求める。\n",
        "* 加重平均の重みは、各テキストにおけるその単語のTF-IDFの値を使って定める。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.sum(0)"
      ],
      "metadata": {
        "id": "LXcUTl7MMI6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxYtetYvEVMt"
      },
      "outputs": [],
      "source": [
        "text_weights = X_train / X_train.sum(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFXVOW-zEVMt"
      },
      "outputs": [],
      "source": [
        "vocab_embeddings = np.dot(text_weights.T, embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDzUNmnaMaUv"
      },
      "source": [
        "## 文書クラスタリング\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings.shape"
      ],
      "metadata": {
        "id": "LutTeRwoPcEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* k-meansのしくみ"
      ],
      "metadata": {
        "id": "_MkO7Nu9RAIz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 初期化"
      ],
      "metadata": {
        "id": "3PH1ezktRCnB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_clusters = 20\n",
        "assignments = np.random.randint(0, n_clusters, X_train.shape[0])"
      ],
      "metadata": {
        "id": "09ybCU_xPeqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assignments"
      ],
      "metadata": {
        "id": "lk5cBMiNReps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* クラスタの重心の計算"
      ],
      "metadata": {
        "id": "MvCtsAWzRuqz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_vectors = []\n",
        "for k in range(n_clusters):\n",
        "  mean_vectors.append(embeddings[assignments == k].mean(0))"
      ],
      "metadata": {
        "id": "Us7sxJFqPvVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_vectors = np.array(mean_vectors)"
      ],
      "metadata": {
        "id": "T_hAjT4VSL_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_vectors"
      ],
      "metadata": {
        "id": "w7NLKW28SSwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 各ベクトルに最も近い重心ベクトルを見つけて、クラスタを割り当て直す"
      ],
      "metadata": {
        "id": "Q8PvxFchSdWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.sqrt(((embeddings[0] - mean_vectors[0]) ** 2).sum())"
      ],
      "metadata": {
        "id": "YhHQeZRtQcYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distances = []\n",
        "for k in range(n_clusters):\n",
        "  distances.append(np.linalg.norm(embeddings[0] - mean_vectors[k]))\n",
        "distances"
      ],
      "metadata": {
        "id": "n-VvSTVsQUGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WO9p70lpNjQ_"
      },
      "source": [
        "### k-平均法によるクラスタリング"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyXb2eRFOo3i"
      },
      "outputs": [],
      "source": [
        "n_clusters = 20\n",
        "kmeans = KMeans(n_clusters=n_clusters, n_init='auto', random_state=123)\n",
        "kmeans.fit(embeddings)\n",
        "#kmeans.fit(content_embeddings) # 本文の場合はこちら。\n",
        "centers = kmeans.cluster_centers_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "centers"
      ],
      "metadata": {
        "id": "js2E7e4nWaPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFLiNhQjNpO2"
      },
      "source": [
        "* クラスタの重心を保存。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9AzNSATqPBIz"
      },
      "outputs": [],
      "source": [
        "with open(f'centers_{n_clusters}.npy', 'wb') as f:\n",
        "  np.save(f, centers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKZu_PGxVHeW"
      },
      "outputs": [],
      "source": [
        "with open(f'centers_{n_clusters}.npy', 'rb') as f:\n",
        "  centers = np.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgtCM75KYSjZ"
      },
      "source": [
        "### クラスタのサイズを調べる"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GC267ESgFqk"
      },
      "source": [
        "* クラスタのインデックスをキーとし、そのサイズを値とする辞書を作る。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEtINadMTpW_"
      },
      "outputs": [],
      "source": [
        "unique, counts = np.unique(kmeans.labels_, return_counts=True)\n",
        "size_dict = dict(zip(unique, counts))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROivZugMgOds"
      },
      "source": [
        "* 辞書のエントリを、キーではなく値でソートする。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41h3OeM9ZF5d"
      },
      "outputs": [],
      "source": [
        "print([sorted(size_dict.items(), key=lambda item: item[1], reverse=True)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ns24Lg8YdVir"
      },
      "source": [
        "## クラスタのラベリング\n",
        "* 各クラスタの重心に近い単語でラベリングする。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* テキストの埋め込みは、長さ1のベクトルになっている。"
      ],
      "metadata": {
        "id": "CzIBc3xLC0vc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.linalg.norm(embeddings, axis=-1)"
      ],
      "metadata": {
        "id": "61Zg_lH3CqEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* テキストとラベリング用の単語との類似度はコサイン類似度で測る。"
      ],
      "metadata": {
        "id": "7HoA3hXQC31b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpaDwQsShEq5"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "similarities = cosine_similarity(vocab_embeddings, centers)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_embeddings.shape"
      ],
      "metadata": {
        "id": "IvwaUm-zXcIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "centers.shape"
      ],
      "metadata": {
        "id": "pbbNtjaeXfCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarities.shape"
      ],
      "metadata": {
        "id": "2JBHL3V4XSdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 重心に近い順に30個の単語を表示する。"
      ],
      "metadata": {
        "id": "4P3OfjmRC9eR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p37FojBHEVMu"
      },
      "outputs": [],
      "source": [
        "for i in range(similarities.shape[-1]):\n",
        "  indices = np.argsort(- similarities[:,i])\n",
        "  print(vocab[indices[:30]])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# プランナー課題１１\n",
        "* それぞれのクラスタについて、重心に近い元々のテキスト（つまり記事タイトル）を5件ずつ表示させてみよう。\n",
        "* それらのテキストの内容に、上で得たラベルが合っているかどうか、確かめよう。"
      ],
      "metadata": {
        "id": "BhRfMIXnXA42"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpwKrF-CFKgz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}